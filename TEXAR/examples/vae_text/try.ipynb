{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "# pylint: disable=invalid-name, no-member, too-many-locals\n",
    "# pylint: disable=too-many-branches, too-many-statements, redefined-variable-type\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import importlib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import texar as tx\n",
    "\n",
    "#flags = tf.flags\n",
    "\n",
    "#flags.DEFINE_string(\"config\", \"config\", \"config_trans_ptb.py\")\n",
    "\n",
    "#FLAGS = flags.FLAGS\n",
    "\n",
    "config = importlib.import_module('config_lstm_mydata')\n",
    "\n",
    "def kl_dvg(means, logvars):\n",
    "    \"\"\"compute the KL divergence between Gaussian distribution\n",
    "    \"\"\"\n",
    "    kl_cost = -0.5 * (logvars - tf.square(means) -\n",
    "                      tf.exp(logvars) + 1.0)\n",
    "    kl_cost = tf.reduce_mean(kl_cost, 0)\n",
    "\n",
    "    return tf.reduce_sum(kl_cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mydata'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_epochs': 1,\n",
       " 'batch_size': 32,\n",
       " 'seed': 123,\n",
       " 'dataset': {'files': './data/mydata/mydata.train.txt',\n",
       "  'vocab_file': './data/mydata/vocab.txt'}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.train_data_hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "train_data = tx.data.MonoTextData(config.train_data_hparams)\n",
    "val_data = tx.data.MonoTextData(config.val_data_hparams)\n",
    "test_data = tx.data.MonoTextData(config.test_data_hparams)\n",
    "iterator = tx.data.TrainTestDataIterator(train=train_data,\n",
    "                                         val=val_data,\n",
    "                                         test=test_data)\n",
    "data_batch = iterator.get_next()\n",
    "\n",
    "opt_vars = {\n",
    "    'learning_rate': config.lr_decay_hparams[\"init_lr\"],\n",
    "    'best_valid_nll': 1e100,\n",
    "    'steps_not_improved': 0,\n",
    "    'kl_weight': config.kl_anneal_hparams[\"start\"]\n",
    "}\n",
    "\n",
    "decay_cnt = 0\n",
    "max_decay = config.lr_decay_hparams[\"max_decay\"]\n",
    "decay_factor = config.lr_decay_hparams[\"decay_factor\"]\n",
    "decay_ts = config.lr_decay_hparams[\"threshold\"]\n",
    "\n",
    "save_dir = \"./models/%s\" % config.dataset\n",
    "\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "suffix = \"%s_%sDecoder.ckpt\" % \\\n",
    "        (config.dataset, config.decoder_hparams[\"type\"])\n",
    "\n",
    "save_path = os.path.join(save_dir, suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./models/mydata'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./models/mydata/mydata_lstmDecoder.ckpt'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KL term annealing rate\n",
    "anneal_r = 1.0 / (config.kl_anneal_hparams[\"warm_up\"] * \\\n",
    "    (train_data.dataset_size() / config.batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anneal_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model architecture\n",
    "embedder = tx.modules.WordEmbedder(\n",
    "    vocab_size=train_data.vocab.size, hparams=config.emb_hparams)\n",
    "\n",
    "\n",
    "input_embed = embedder(data_batch[\"text_ids\"])\n",
    "output_embed = embedder(data_batch[\"text_ids\"][:, :-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.enc_keep_prob_in < 1:\n",
    "    input_embed = tf.nn.dropout(\n",
    "        input_embed, tx.utils.switch_dropout(config.enc_keep_prob_in))\n",
    "\n",
    "if config.dec_keep_prob_in < 1:\n",
    "    output_embed = tf.nn.dropout(\n",
    "        output_embed, tx.utils.switch_dropout(config.dec_keep_prob_in))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = tx.modules.UnidirectionalRNNEncoder(\n",
    "    hparams={\"rnn_cell\": config.enc_cell_hparams})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<texar.modules.encoders.rnn_encoders.UnidirectionalRNNEncoder at 0x7f82b7124860>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.decoder_hparams[\"type\"] == \"lstm\":\n",
    "    decoder = tx.modules.BasicRNNDecoder(\n",
    "        vocab_size=train_data.vocab.size,\n",
    "        hparams={\"rnn_cell\": config.dec_cell_hparams})\n",
    "    decoder_initial_state_size = decoder.cell.state_size\n",
    "elif config.decoder_hparams[\"type\"] == 'transformer':\n",
    "    decoder = tx.modules.TransformerDecoder(\n",
    "        embedding=embedder.embedding,\n",
    "        hparams=config.trans_hparams)\n",
    "    decoder_initial_state_size = tf.TensorShape(\n",
    "        [1, config.emb_hparams[\"dim\"]])\n",
    "else:\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-14-d272e07eb0cb>:17: MultivariateNormalDiag.__init__ (from tensorflow.contrib.distributions.python.ops.mvn_diag) is deprecated and will be removed after 2018-10-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n",
      "WARNING:tensorflow:From /home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/tensorflow/contrib/distributions/python/ops/mvn_diag.py:223: MultivariateNormalLinearOperator.__init__ (from tensorflow.contrib.distributions.python.ops.mvn_linear_operator) is deprecated and will be removed after 2018-10-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n",
      "WARNING:tensorflow:From /home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/tensorflow/contrib/distributions/python/ops/mvn_linear_operator.py:200: AffineLinearOperator.__init__ (from tensorflow.contrib.distributions.python.ops.bijectors.affine_linear_operator) is deprecated and will be removed after 2018-10-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n",
      "WARNING:tensorflow:From /home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/tensorflow/contrib/distributions/python/ops/bijectors/affine_linear_operator.py:158: _DistributionShape.__init__ (from tensorflow.contrib.distributions.python.ops.shape) is deprecated and will be removed after 2018-10-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n"
     ]
    }
   ],
   "source": [
    "connector_mlp = tx.modules.MLPTransformConnector(\n",
    "    config.latent_dims * 2)\n",
    "\n",
    "connector_stoch = tx.modules.ReparameterizedStochasticConnector(\n",
    "    decoder_initial_state_size)\n",
    "\n",
    "_, ecdr_states = encoder(\n",
    "    input_embed,\n",
    "    sequence_length=data_batch[\"length\"])\n",
    "\n",
    "mean_logvar = connector_mlp(ecdr_states)\n",
    "mean, logvar = tf.split(mean_logvar, 2, 1)\n",
    "kl_loss = kl_dvg(mean, logvar)\n",
    "\n",
    "dst = tf.contrib.distributions.MultivariateNormalDiag(\n",
    "    loc=mean,\n",
    "    scale_diag=tf.exp(0.5 * logvar))\n",
    "\n",
    "dcdr_states, _ = connector_stoch(dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder\n",
    "if config.decoder_hparams[\"type\"] == \"lstm\":\n",
    "    outputs, _, _ = decoder(\n",
    "        initial_state=dcdr_states,\n",
    "        decoding_strategy=\"train_greedy\",\n",
    "        inputs=output_embed,\n",
    "        sequence_length=data_batch[\"length\"]-1)\n",
    "else:\n",
    "    outputs = decoder(\n",
    "        inputs=output_embed,\n",
    "        memory=dcdr_states,\n",
    "        memory_sequence_length=tf.ones(tf.shape(dcdr_states)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = outputs.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_lengths = data_batch[\"length\"] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Losses & train ops\n",
    "rc_loss = tx.losses.sequence_sparse_softmax_cross_entropy(\n",
    "    labels=data_batch[\"text_ids\"][:, 1:],\n",
    "    logits=logits,\n",
    "    sequence_length=data_batch[\"length\"]-1)\n",
    "\n",
    "# KL annealing\n",
    "kl_weight = tf.placeholder(tf.float32, shape=())\n",
    "\n",
    "nll = rc_loss + kl_weight * kl_loss\n",
    "\n",
    "learning_rate = tf.placeholder(dtype=tf.float32, shape=(),\n",
    "                               name='learning_rate')\n",
    "train_op = tx.core.get_train_op(nll, learning_rate=learning_rate,\n",
    "                                hparams=config.opt_hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(tf.local_variables_initializer())\n",
    "sess.run(tf.tables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7521060 total parameters\n"
     ]
    }
   ],
   "source": [
    "# Counts trainable parameters\n",
    "total_parameters = 0\n",
    "for variable in tf.trainable_variables():\n",
    "    shape = variable.get_shape() # shape is an array of tf.Dimension\n",
    "    variable_parameters = 1\n",
    "    for dim in shape:\n",
    "        variable_parameters *= dim.value\n",
    "    total_parameters += variable_parameters\n",
    "print(\"%d total parameters\" % total_parameters)\n",
    "\n",
    "best_nll = best_ppl = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '_run_epoch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-55a530d9ff95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mval_nll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'valid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_nll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_ppl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name '_run_epoch' is not defined"
     ]
    }
   ],
   "source": [
    "_, _ = _run_epoch(sess, epoch, 'train', display=200)\n",
    "val_nll, _ = _run_epoch(sess, epoch, 'valid')\n",
    "test_nll, test_ppl = _run_epoch(sess, epoch, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_string = 'test'\n",
    "iterator.switch_to_test_data(sess)\n",
    "\n",
    "step = 0\n",
    "start_time = time.time()\n",
    "num_words = num_sents = 0\n",
    "nll_ = 0.\n",
    "kl_loss_ = rc_loss_ = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetches = {\"nll\": nll,\n",
    "           \"kl_loss\": kl_loss,\n",
    "           \"rc_loss\": rc_loss,\n",
    "           \"lengths\": seq_lengths}\n",
    "if mode_string == 'train':\n",
    "    fetches[\"train_op\"] = train_op\n",
    "    opt_vars[\"kl_weight\"] = min(\n",
    "        1.0, opt_vars[\"kl_weight\"] + anneal_r)\n",
    "\n",
    "    kl_weight_ = opt_vars[\"kl_weight\"]\n",
    "else:\n",
    "    kl_weight_ = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nll': <tf.Tensor 'add_1:0' shape=() dtype=float32>,\n",
       " 'kl_loss': <tf.Tensor 'Sum:0' shape=() dtype=float32>,\n",
       " 'rc_loss': <tf.Tensor 'sequence_sparse_softmax_cross_entropy/Mean:0' shape=() dtype=float32>,\n",
       " 'lengths': <tf.Tensor 'sub_4:0' shape=(?,) dtype=int32>}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfRangeError",
     "evalue": "End of sequence\n\t [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[[?], [?,?], [?,?]], output_types=[DT_INT32, DT_STRING, DT_INT64], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](data_iterator_1/Iterator)]]\n\nCaused by op 'IteratorGetNext', defined at:\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/asyncio/base_events.py\", line 1434, in _run_once\n    handle._run()\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-4-bcfa53e37f28>\", line 8, in <module>\n    data_batch = iterator.get_next()\n  File \"/home/guojy/texar/texar/data/data/data_iterators.py\", line 167, in get_next\n    return self._iterator.get_next()\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py\", line 410, in get_next\n    name=name)), self._output_types,\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/tensorflow/python/ops/gen_dataset_ops.py\", line 2069, in iterator_get_next\n    output_shapes=output_shapes, name=name)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nOutOfRangeError (see above for traceback): End of sequence\n\t [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[[?], [?,?], [?,?]], output_types=[DT_INT32, DT_STRING, DT_INT64], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](data_iterator_1/Iterator)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfRangeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/pt4/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pt4/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1263\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pt4/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOutOfRangeError\u001b[0m: End of sequence\n\t [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[[?], [?,?], [?,?]], output_types=[DT_INT32, DT_STRING, DT_INT64], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](data_iterator_1/Iterator)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOutOfRangeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-5f081effb51e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m         learning_rate: opt_vars[\"learning_rate\"]}\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mfetches_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"lengths\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pt4/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pt4/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1100\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pt4/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1272\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1273\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pt4/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1289\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1291\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1293\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOutOfRangeError\u001b[0m: End of sequence\n\t [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[[?], [?,?], [?,?]], output_types=[DT_INT32, DT_STRING, DT_INT64], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](data_iterator_1/Iterator)]]\n\nCaused by op 'IteratorGetNext', defined at:\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/asyncio/base_events.py\", line 1434, in _run_once\n    handle._run()\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-4-bcfa53e37f28>\", line 8, in <module>\n    data_batch = iterator.get_next()\n  File \"/home/guojy/texar/texar/data/data/data_iterators.py\", line 167, in get_next\n    return self._iterator.get_next()\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py\", line 410, in get_next\n    name=name)), self._output_types,\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/tensorflow/python/ops/gen_dataset_ops.py\", line 2069, in iterator_get_next\n    output_shapes=output_shapes, name=name)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nOutOfRangeError (see above for traceback): End of sequence\n\t [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[[?], [?,?], [?,?]], output_types=[DT_INT32, DT_STRING, DT_INT64], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](data_iterator_1/Iterator)]]\n"
     ]
    }
   ],
   "source": [
    "mode = (tf.estimator.ModeKeys.TRAIN if mode_string == 'train'\n",
    "        else tf.estimator.ModeKeys.EVAL)\n",
    "\n",
    "feed = {tx.global_mode(): mode,\n",
    "        kl_weight: kl_weight_,\n",
    "        learning_rate: opt_vars[\"learning_rate\"]}\n",
    "\n",
    "fetches_ = sess.run(fetches, feed_dict=feed)\n",
    "\n",
    "batch_size = len(fetches_[\"lengths\"])\n",
    "num_sents += batch_size\n",
    "\n",
    "num_words += sum(fetches_[\"lengths\"])\n",
    "nll_ += fetches_[\"nll\"] * batch_size\n",
    "kl_loss_ += fetches_[\"kl_loss\"] * batch_size\n",
    "rc_loss_ += fetches_[\"rc_loss\"] * batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = sess.run({'rec':outputs.sample_id[0],'ref':data_batch['text_ids'][0]},feed_dict=feed)\n",
    "dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rec': array([[7938, 2324, 2324, ..., 6370, 6370, 6370],\n",
       "        [2445, 7701, 2324, ..., 6680,  742, 6370],\n",
       "        [4906, 2765, 2765, ..., 6370, 6370, 6370],\n",
       "        ...,\n",
       "        [6581, 9580, 9564, ..., 6370, 6370, 6370],\n",
       "        [4009, 4009, 4009, ..., 6370, 6370, 6370],\n",
       "        [3867, 8481, 8481, ..., 6370, 6370, 6370]], dtype=int32),\n",
       " 'ref': array([[   1,    4,    5, ...,    0,    0,    0],\n",
       "        [   1,   14,    4, ...,    0,    0,    0],\n",
       "        [   1,  135,   24, ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [   1,   63,  296, ...,    0,    0,    0],\n",
       "        [   1,    6,   13, ...,    0,    0,    0],\n",
       "        [   1, 2368,   90, ...,    0,    0,    0]])}"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic = sess.run({'rec':outputs.sample_id,'ref':data_batch['text_ids']},feed_dict=feed)\n",
    "dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7938, 2324, 2324, 2324, 3019, 1318,  136,  429, 8868, 5695, 3146,\n",
       "       3649, 7401, 6932, 8520, 4061, 8375, 5021, 8047,  982, 6242, 9651,\n",
       "        350, 9651, 7011, 1471,  742, 5499, 6370, 6370, 6370, 6370, 6370,\n",
       "       6370, 6370, 6370, 6370, 6370], dtype=int32)"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic['rec'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 46)"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic['rec'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 47)"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic['ref'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tap mural mural mural absolutely survived vacation alleges colonial rick steppenwolf wants spreads coors shippers fda junk coming credibility miami-based generation whitten vincent emerging assumptions dayton corrupt corrupt corrupt corrupt corrupt corrupt corrupt corrupt corrupt corrupt corrupt corrupt corrupt corrupt\n",
      "\n",
      "\n",
      "<BOS> lincoln 's parent company american continental corp. entered bankruptcy-law proceedings this april N and regulators seized the thrift the next day <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    }
   ],
   "source": [
    "print(' '.join([train_data.vocab.id_to_token_map_py[i] for i in dic['rec'][1]]))\n",
    "print('\\n')\n",
    "print(' '.join([train_data.vocab.id_to_token_map_py[i] for i in dic['ref'][1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<BOS> his advice you ought to be there with a basket catching them <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>'"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref = sess.run(data_batch['text_ids'][0],feed_dict=feed)\n",
    "' '.join([train_data.vocab.id_to_token_map_py[i] for i in ref])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1318, 5908, 9419, 2495,   40, 8161, 9666, 2174, 2955, 5722, 9123,\n",
       "       4445, 5977, 2123, 1608, 9419, 7903, 3009, 5599,  171, 4115, 7563,\n",
       "       8803, 3633, 3828, 3342, 5029,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0], dtype=int32)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec = sess.run(outputs.sample_id[0],feed_dict=feed)\n",
    "rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'measures arrive sights memory company inland discouraged generation scenario manner loaded column cosby audience consulting sights brewer downward bearing month examination monopolies crashes row exchequer academic sweetened <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join([train_data.vocab.id_to_token_map_py[i] for i in rec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/ptb/ptb_lstmDecoder.ckpt\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nKey OptimizeLoss_1/basic_rnn_decoder/decoder/dense/bias/Adam not found in checkpoint\n\t [[Node: save_2/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save_2/Const_0_0, save_2/RestoreV2/tensor_names, save_2/RestoreV2/shape_and_slices)]]\n\nCaused by op 'save_2/RestoreV2', defined at:\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/asyncio/base_events.py\", line 1434, in _run_once\n    handle._run()\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-253-416a2593f909>\", line 1, in <module>\n    saver = tf.train.Saver()\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1281, in __init__\n    self.build()\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1293, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1330, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 778, in _build_internal\n    restore_sequentially, reshape)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 397, in _AddRestoreOps\n    restore_sequentially)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 829, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1463, in restore_v2\n    shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nNotFoundError (see above for traceback): Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nKey OptimizeLoss_1/basic_rnn_decoder/decoder/dense/bias/Adam not found in checkpoint\n\t [[Node: save_2/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save_2/Const_0_0, save_2/RestoreV2/tensor_names, save_2/RestoreV2/shape_and_slices)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/pt4/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pt4/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1263\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pt4/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Key OptimizeLoss_1/basic_rnn_decoder/decoder/dense/bias/Adam not found in checkpoint\n\t [[Node: save_2/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save_2/Const_0_0, save_2/RestoreV2/tensor_names, save_2/RestoreV2/shape_and_slices)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/pt4/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1724\u001b[0m         sess.run(self.saver_def.restore_op_name,\n\u001b[0;32m-> 1725\u001b[0;31m                  {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[1;32m   1726\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pt4/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pt4/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1100\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pt4/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1272\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1273\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pt4/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1290\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1291\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Key OptimizeLoss_1/basic_rnn_decoder/decoder/dense/bias/Adam not found in checkpoint\n\t [[Node: save_2/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save_2/Const_0_0, save_2/RestoreV2/tensor_names, save_2/RestoreV2/shape_and_slices)]]\n\nCaused by op 'save_2/RestoreV2', defined at:\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/asyncio/base_events.py\", line 1434, in _run_once\n    handle._run()\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-253-416a2593f909>\", line 1, in <module>\n    saver = tf.train.Saver()\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1281, in __init__\n    self.build()\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1293, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1330, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 778, in _build_internal\n    restore_sequentially, reshape)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 397, in _AddRestoreOps\n    restore_sequentially)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 829, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1463, in restore_v2\n    shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nNotFoundError (see above for traceback): Key OptimizeLoss_1/basic_rnn_decoder/decoder/dense/bias/Adam not found in checkpoint\n\t [[Node: save_2/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save_2/Const_0_0, save_2/RestoreV2/tensor_names, save_2/RestoreV2/shape_and_slices)]]\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/pt4/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1736\u001b[0m         object_graph_string = reader.get_tensor(\n\u001b[0;32m-> 1737\u001b[0;31m             checkpointable.OBJECT_GRAPH_PROTO_KEY)\n\u001b[0m\u001b[1;32m   1738\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pt4/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36mget_tensor\u001b[0;34m(self, tensor_str)\u001b[0m\n\u001b[1;32m    350\u001b[0m         return CheckpointReader_GetTensor(self, compat.as_bytes(tensor_str),\n\u001b[0;32m--> 351\u001b[0;31m                                           status)\n\u001b[0m\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pt4/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    520\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-255-b526ae8fb0e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pt4/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1741\u001b[0m         \u001b[0;31m# a helpful message (b/110263146)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1742\u001b[0m         raise _wrap_restore_error_with_msg(\n\u001b[0;32m-> 1743\u001b[0;31m             err, \"a Variable name or other graph key that is missing\")\n\u001b[0m\u001b[1;32m   1744\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       \u001b[0;31m# This is an object-based checkpoint. We'll print a warning and then do\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nKey OptimizeLoss_1/basic_rnn_decoder/decoder/dense/bias/Adam not found in checkpoint\n\t [[Node: save_2/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save_2/Const_0_0, save_2/RestoreV2/tensor_names, save_2/RestoreV2/shape_and_slices)]]\n\nCaused by op 'save_2/RestoreV2', defined at:\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/asyncio/base_events.py\", line 1434, in _run_once\n    handle._run()\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-253-416a2593f909>\", line 1, in <module>\n    saver = tf.train.Saver()\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1281, in __init__\n    self.build()\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1293, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1330, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 778, in _build_internal\n    restore_sequentially, reshape)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 397, in _AddRestoreOps\n    restore_sequentially)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 829, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1463, in restore_v2\n    shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nNotFoundError (see above for traceback): Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nKey OptimizeLoss_1/basic_rnn_decoder/decoder/dense/bias/Adam not found in checkpoint\n\t [[Node: save_2/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save_2/Const_0_0, save_2/RestoreV2/tensor_names, save_2/RestoreV2/shape_and_slices)]]\n"
     ]
    }
   ],
   "source": [
    "saver.restore(sess, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _run_epoch(sess, epoch, mode_string, display=10):\n",
    "    if mode_string == 'train':\n",
    "        iterator.switch_to_train_data(sess)\n",
    "    elif mode_string == 'valid':\n",
    "        iterator.switch_to_val_data(sess)\n",
    "    elif mode_string == 'test':\n",
    "        iterator.switch_to_test_data(sess)\n",
    "\n",
    "    step = 0\n",
    "    start_time = time.time()\n",
    "    num_words = num_sents = 0\n",
    "    nll_ = 0.\n",
    "    kl_loss_ = rc_loss_ = 0.\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            fetches = {\"nll\": nll,\n",
    "                       \"kl_loss\": kl_loss,\n",
    "                       \"rc_loss\": rc_loss,\n",
    "                       \"lengths\": seq_lengths}\n",
    "\n",
    "            if mode_string == 'train':\n",
    "                fetches[\"train_op\"] = train_op\n",
    "                opt_vars[\"kl_weight\"] = min(\n",
    "                    1.0, opt_vars[\"kl_weight\"] + anneal_r)\n",
    "\n",
    "                kl_weight_ = opt_vars[\"kl_weight\"]\n",
    "            else:\n",
    "                kl_weight_ = 1.0\n",
    "\n",
    "            mode = (tf.estimator.ModeKeys.TRAIN if mode_string == 'train'\n",
    "                    else tf.estimator.ModeKeys.EVAL)\n",
    "\n",
    "            feed = {tx.global_mode(): mode,\n",
    "                    kl_weight: kl_weight_,\n",
    "                    learning_rate: opt_vars[\"learning_rate\"]}\n",
    "\n",
    "            fetches_ = sess.run(fetches, feed_dict=feed)\n",
    "\n",
    "            batch_size = len(fetches_[\"lengths\"])\n",
    "            num_sents += batch_size\n",
    "\n",
    "            num_words += sum(fetches_[\"lengths\"])\n",
    "            nll_ += fetches_[\"nll\"] * batch_size\n",
    "            kl_loss_ += fetches_[\"kl_loss\"] * batch_size\n",
    "            rc_loss_ += fetches_[\"rc_loss\"] * batch_size\n",
    "\n",
    "            if step % display == 0 and mode_string == 'train':\n",
    "                print('%s: epoch %d, step %d, nll %.4f, klw: %.4f, ' \\\n",
    "                       'KL %.4f,  rc %.4f, log_ppl %.4f, ppl %.4f, ' \\\n",
    "                       'time elapsed: %.1fs' % \\\n",
    "                      (mode_string, epoch, step, nll_ / num_sents,\n",
    "                       opt_vars[\"kl_weight\"], kl_loss_ / num_sents,\n",
    "                       rc_loss_ / num_sents, nll_ / num_words,\n",
    "                       np.exp(nll_ / num_words), time.time() - start_time))\n",
    "\n",
    "                sys.stdout.flush()\n",
    "\n",
    "            step += 1\n",
    "\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print('\\n%s: epoch %d, nll %.4f, KL %.4f, rc %.4f, ' \\\n",
    "                  'log_ppl %.4f, ppl %.4f\\n' %\n",
    "                  (mode_string, epoch, nll_ / num_sents,\n",
    "                   kl_loss_ / num_sents, rc_loss_ / num_sents,\n",
    "                   nll_ / num_words, np.exp(nll_ / num_words)))\n",
    "            break\n",
    "\n",
    "    return nll_ / num_sents, np.exp(nll_ / num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18795987 total parameters\n",
      "train: epoch 0, step 0, nll 322.3953, klw: 0.1002, KL 0.0106,  rc 322.3942, log_ppl 14.1131, ppl 1346557.8560, time elapsed: 2.7s\n",
      "train: epoch 0, step 200, nll 173.2578, klw: 0.1154, KL 2.4226,  rc 172.9999, log_ppl 7.8037, ppl 2449.6856, time elapsed: 239.0s\n",
      "train: epoch 0, step 400, nll 157.0820, klw: 0.1306, KL 1.4062,  rc 156.9297, log_ppl 7.0718, ppl 1178.2695, time elapsed: 482.6s\n",
      "train: epoch 0, step 600, nll 149.6566, klw: 0.1458, KL 0.9452,  rc 149.5541, log_ppl 6.7545, ppl 857.9290, time elapsed: 729.2s\n",
      "train: epoch 0, step 800, nll 145.2516, klw: 0.1610, KL 0.7182,  rc 145.1732, log_ppl 6.5561, ppl 703.5114, time elapsed: 982.6s\n",
      "train: epoch 0, step 1000, nll 141.8951, klw: 0.1762, KL 0.6362,  rc 141.8219, log_ppl 6.4119, ppl 609.0537, time elapsed: 1227.1s\n",
      "train: epoch 0, step 1200, nll 139.3261, klw: 0.1914, KL 0.6286,  rc 139.2470, log_ppl 6.3038, ppl 546.6211, time elapsed: 1455.8s\n",
      "\n",
      "train: epoch 0, nll 138.1212, KL 0.6371, rc 138.0366, log_ppl 6.2506, ppl 518.3192\n",
      "\n",
      "\n",
      "valid: epoch 0, nll 122.4726, KL 0.9889, rc 121.4837, log_ppl 5.5956, ppl 269.2429\n",
      "\n",
      "\n",
      "test: epoch 0, nll 121.4439, KL 0.8737, rc 120.5701, log_ppl 5.5411, ppl 254.9504\n",
      "\n",
      "train: epoch 1, step 0, nll 132.2007, klw: 0.2003, KL 0.9351,  rc 132.0134, log_ppl 5.7872, ppl 326.0889, time elapsed: 1.1s\n",
      "train: epoch 1, step 200, nll 124.3974, klw: 0.2155, KL 0.7713,  rc 124.2368, log_ppl 5.6030, ppl 271.2361, time elapsed: 236.7s\n",
      "train: epoch 1, step 400, nll 123.9952, klw: 0.2307, KL 0.7932,  rc 123.8240, log_ppl 5.5822, ppl 265.6666, time elapsed: 480.3s\n",
      "train: epoch 1, step 600, nll 123.1306, klw: 0.2459, KL 0.8046,  rc 122.9508, log_ppl 5.5573, ppl 259.1252, time elapsed: 722.0s\n",
      "train: epoch 1, step 800, nll 122.6151, klw: 0.2611, KL 0.8119,  rc 122.4274, log_ppl 5.5344, ppl 253.2464, time elapsed: 975.1s\n",
      "train: epoch 1, step 1000, nll 121.9383, klw: 0.2763, KL 0.8280,  rc 121.7402, log_ppl 5.5101, ppl 247.1777, time elapsed: 1221.1s\n",
      "train: epoch 1, step 1200, nll 121.3367, klw: 0.2915, KL 0.8311,  rc 121.1316, log_ppl 5.4898, ppl 242.2170, time elapsed: 1449.3s\n",
      "\n",
      "train: epoch 1, nll 121.0554, KL 0.8385, rc 120.8445, log_ppl 5.4783, ppl 239.4368\n",
      "\n",
      "\n",
      "valid: epoch 1, nll 115.8374, KL 0.8178, rc 115.0195, log_ppl 5.2925, ppl 198.8322\n",
      "\n",
      "\n",
      "test: epoch 1, nll 114.7059, KL 0.7460, rc 113.9600, log_ppl 5.2336, ppl 187.4740\n",
      "\n",
      "train: epoch 2, step 0, nll 124.2886, klw: 0.3004, KL 0.7560,  rc 124.0615, log_ppl 5.4408, ppl 230.6296, time elapsed: 1.1s\n",
      "train: epoch 2, step 200, nll 117.7712, klw: 0.3156, KL 0.9221,  rc 117.4871, log_ppl 5.3045, ppl 201.2487, time elapsed: 238.0s\n",
      "train: epoch 2, step 400, nll 117.6595, klw: 0.3308, KL 0.9550,  rc 117.3578, log_ppl 5.2970, ppl 199.7386, time elapsed: 481.1s\n",
      "train: epoch 2, step 600, nll 117.0805, klw: 0.3460, KL 1.0093,  rc 116.7533, log_ppl 5.2843, ppl 197.2062, time elapsed: 722.9s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-101-9ab8c2bc1cfc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mval_nll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'valid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mtest_nll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_ppl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-95-a770da233a68>\u001b[0m in \u001b[0;36m_run_epoch\u001b[0;34m(sess, epoch, mode_string, display)\u001b[0m\n\u001b[1;32m     36\u001b[0m                     learning_rate: opt_vars[\"learning_rate\"]}\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0mfetches_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"lengths\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pt4/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pt4/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pt4/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pt4/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pt4/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pt4/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    sess.run(tf.tables_initializer())\n",
    "\n",
    "    # Counts trainable parameters\n",
    "    total_parameters = 0\n",
    "    for variable in tf.trainable_variables():\n",
    "        shape = variable.get_shape() # shape is an array of tf.Dimension\n",
    "        variable_parameters = 1\n",
    "        for dim in shape:\n",
    "            variable_parameters *= dim.value\n",
    "        total_parameters += variable_parameters\n",
    "    print(\"%d total parameters\" % total_parameters)\n",
    "\n",
    "    best_nll = best_ppl = 0.\n",
    "\n",
    "    for epoch in range(10):\n",
    "        _, _ = _run_epoch(sess, epoch, 'train', display=200)\n",
    "        val_nll, _ = _run_epoch(sess, epoch, 'valid')\n",
    "        test_nll, test_ppl = _run_epoch(sess, epoch, 'test')\n",
    "\n",
    "        if val_nll < opt_vars['best_valid_nll']:\n",
    "            opt_vars['best_valid_nll'] = val_nll\n",
    "            opt_vars['steps_not_improved'] = 0\n",
    "            best_nll = test_nll\n",
    "            best_ppl = test_ppl\n",
    "            #saver.save(sess, save_path)\n",
    "        else:\n",
    "            opt_vars['steps_not_improved'] += 1\n",
    "            if opt_vars['steps_not_improved'] == decay_ts:\n",
    "                old_lr = opt_vars['learning_rate']\n",
    "                opt_vars['learning_rate'] *= decay_factor\n",
    "                opt_vars['steps_not_improved'] = 0\n",
    "                new_lr = opt_vars['learning_rate']\n",
    "\n",
    "                print('-----\\nchange lr, old lr: %f, new lr: %f\\n-----' %\n",
    "                      (old_lr, new_lr))\n",
    "\n",
    "                #saver.restore(sess, save_path)\n",
    "\n",
    "                decay_cnt += 1\n",
    "                if decay_cnt == max_decay:\n",
    "                    break\n",
    "    \n",
    "    # Beam search decoding\n",
    "    outputs_bs, _, _ = tx.modules.beam_search_decode(\n",
    "    decoder,\n",
    "    embedding=embedder,\n",
    "    start_tokens=[train_data.vocab.bos_token_id]*3,\n",
    "    end_token=train_data.vocab.eos_token_id,\n",
    "    beam_width = 3)\n",
    "    \n",
    "    print(\"outputs_bs\",outputs_bs)\n",
    "                    \n",
    "                    \n",
    "    print('\\nbest testing nll: %.4f, best testing ppl %.4f\\n' %\n",
    "          (best_nll, best_ppl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs_bs <class 'tensorflow.contrib.seq2seq.python.ops.beam_search_decoder.FinalBeamSearchDecoderOutput'>\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    # Beam search decoding\n",
    "    outputs_bs, _, _ = tx.modules.beam_search_decode(\n",
    "    decoder,\n",
    "    embedding=embedder,\n",
    "    start_tokens=[train_data.vocab.bos_token_id]*3,\n",
    "    end_token=train_data.vocab.eos_token_id,\n",
    "    beam_width = 3)\n",
    "    print(\"outputs_bs\",type(outputs_bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import texar as tx\n",
    "\n",
    "# Data \n",
    "\n",
    "data = tx.data.PairedTextData(hparams=config.train_data_hparams) # Hyperparameter configs in `hparams` \n",
    "iterator = tx.data.DataIterator(data)\n",
    "batch = iterator.get_next() # A data mini-batch\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Model architecture\n",
    "embedder = tx.modules.WordEmbedder(data.target_vocab.size, hparams=hparams_emb)\n",
    "encoder = tx.modules.TransformerEncoder(hparams=hparams_encoder)\n",
    "outputs_enc = encoder(inputs=embedder(batch['source_text_ids']),\n",
    "                      sequence_length=batch['source_length'])\n",
    "                      \n",
    "decoder = tx.modules.AttentionRNNDecoder(memory=output_enc, \n",
    "                                         memory_sequence_length=batch['source_length'],\n",
    "                                         hparams=hparams_decoder)\n",
    "outputs, _, _ = decoder(inputs=embedder(batch['target_text_ids']),\n",
    "                        sequence_length=batch['target_length']-1)\n",
    "                        \n",
    "# Loss for maximum likelihood learning\n",
    "loss = tx.losses.sequence_sparse_softmax_cross_entropy(\n",
    "    labels=batch['target_text_ids'][:, 1:],\n",
    "    logits=outputs.logits,\n",
    "    sequence_length=batch['target_length']-1) # Automatic masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<texar.modules.decoders.transformer_decoders.TransformerDecoder at 0x7f02a80d2a58>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beam search decoding\n",
    "outputs_bs, _, _ = tx.modules.beam_search_decode(\n",
    "    decoder,\n",
    "    embedding=embedder,\n",
    "    start_tokens=[train_data.vocab.bos_token_id]*3,\n",
    "    end_token=train_data.vocab.eos_token_id,\n",
    "    beam_width = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__add__',\n",
       " '__class__',\n",
       " '__contains__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__getnewargs__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__rmul__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '_asdict',\n",
       " '_fields',\n",
       " '_make',\n",
       " '_replace',\n",
       " '_source',\n",
       " 'beam_search_decoder_output',\n",
       " 'count',\n",
       " 'index',\n",
       " 'predicted_ids']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(outputs_bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__add__',\n",
       " '__class__',\n",
       " '__contains__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__getnewargs__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__rmul__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '_asdict',\n",
       " '_fields',\n",
       " '_make',\n",
       " '_replace',\n",
       " '_source',\n",
       " 'count',\n",
       " 'index',\n",
       " 'parent_ids',\n",
       " 'predicted_ids',\n",
       " 'scores']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_bs.beam_search_decoder_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'basic_rnn_decoder_6/decoder/transpose_1:0' shape=(3, ?, 3) dtype=float32>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_bs.beam_search_decoder_output.scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
