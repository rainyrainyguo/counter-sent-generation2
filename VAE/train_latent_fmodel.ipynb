{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# male_sent_obftrain_less100.tsv has total 9610 reviews 712KB\\n# female_sent_obfandclass_less100.tsv has total 9707 reviews 723KB\\n# 上面两个数据集加在一起：all_sent_trainVAE_less100.tsv\\n# 现在用这两个训练\\n\\nwith open('../sent/ori_gender_data/male_sent_obftrain_less100.tsv','r') as f:\\n    mo = f.readlines()\\n\\nwith open('../sent/ori_gender_data/female_sent_obfandclass_less100.tsv','r') as f:\\n    fo = f.readlines()\\n\\nallo = []\\nallo.extend(mo)\\nallo.extend(fo)\\n\\nimport random\\nrandom.shuffle(allo)\\n\\nwith open('../sent/ori_gender_data/all_sent_trainVAE_less100.tsv','w') as f:\\n    for line in allo:\\n        f.write(line)\\n\""
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# male_sent_obftrain_less100.tsv has total 9610 reviews 712KB\n",
    "# female_sent_obfandclass_less100.tsv has total 9707 reviews 723KB\n",
    "# 上面两个数据集加在一起：all_sent_trainVAE_less100.tsv\n",
    "# 现在用这两个训练\n",
    "\n",
    "with open('../sent/ori_gender_data/male_sent_obftrain_less100.tsv','r') as f:\n",
    "    mo = f.readlines()\n",
    "\n",
    "with open('../sent/ori_gender_data/female_sent_obfandclass_less100.tsv','r') as f:\n",
    "    fo = f.readlines()\n",
    "\n",
    "allo = []\n",
    "allo.extend(mo)\n",
    "allo.extend(fo)\n",
    "\n",
    "import random\n",
    "random.shuffle(allo)\n",
    "\n",
    "with open('../sent/ori_gender_data/all_sent_trainVAE_less100.tsv','w') as f:\n",
    "    for line in allo:\n",
    "        f.write(line)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self,z_dim,dropout):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        #self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        #self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(z_dim, 100)\n",
    "        self.fc2 = nn.Linear(100, 60)\n",
    "        self.fc3 = nn.Linear(60, 1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        #x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        #x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        #x = x.view(-1, self.num_flat_features(x))\n",
    "        #x = F.relu(self.fc1(x))\n",
    "        #x = F.relu(self.fc2(x))\n",
    "        #x = self.fc3(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)  \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from itertools import chain\n",
    "from torchtext import data\n",
    "\n",
    "\n",
    "class RNN_VAE(nn.Module):\n",
    "    \"\"\"\n",
    "    1. Hu, Zhiting, et al. \"Toward controlled generation of text.\" ICML. 2017.\n",
    "    2. Bowman, Samuel R., et al. \"Generating sentences from a continuous space.\" arXiv preprint arXiv:1511.06349 (2015).\n",
    "    3. Kim, Yoon. \"Convolutional neural networks for sentence classification.\" arXiv preprint arXiv:1408.5882 (2014).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_vocab, h_dim, z_dim, p_word_dropout=0.3, unk_idx=0, pad_idx=1, start_idx=2, eos_idx=3, max_sent_len=15, pretrained_embeddings=None, freeze_embeddings=False, gpu=False):\n",
    "        super(RNN_VAE, self).__init__()\n",
    "\n",
    "        self.UNK_IDX = unk_idx\n",
    "        self.PAD_IDX = pad_idx\n",
    "        self.START_IDX = start_idx\n",
    "        self.EOS_IDX = eos_idx\n",
    "        self.MAX_SENT_LEN = max_sent_len\n",
    "\n",
    "        self.n_vocab = n_vocab\n",
    "        self.h_dim = h_dim\n",
    "        self.z_dim = z_dim\n",
    "        self.p_word_dropout = p_word_dropout\n",
    "\n",
    "        self.gpu = gpu\n",
    "\n",
    "        \"\"\"\n",
    "        Word embeddings layer\n",
    "        \"\"\"\n",
    "        if pretrained_embeddings is None:\n",
    "            self.emb_dim = h_dim\n",
    "            self.word_emb = nn.Embedding(n_vocab, h_dim, self.PAD_IDX)\n",
    "        else:\n",
    "            self.emb_dim = pretrained_embeddings.size(1)\n",
    "            self.word_emb = nn.Embedding(n_vocab, self.emb_dim, self.PAD_IDX)\n",
    "\n",
    "            # Set pretrained embeddings\n",
    "            self.word_emb.weight.data.copy_(pretrained_embeddings)\n",
    "\n",
    "            if freeze_embeddings:\n",
    "                self.word_emb.weight.requires_grad = False\n",
    "\n",
    "        \"\"\"\n",
    "        Encoder is GRU with FC layers connected to last hidden unit\n",
    "        \"\"\"\n",
    "        self.encoder = nn.GRU(self.emb_dim, h_dim)\n",
    "        self.q_mu = nn.Linear(h_dim, z_dim)\n",
    "        self.q_logvar = nn.Linear(h_dim, z_dim)\n",
    "\n",
    "        \"\"\"\n",
    "        Decoder is GRU with `z` and `c` appended at its inputs\n",
    "        \"\"\"\n",
    "        self.decoder = nn.GRU(self.emb_dim+z_dim, z_dim, dropout=0.3)\n",
    "        self.decoder_fc = nn.Linear(z_dim, n_vocab)\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        Grouping the model's parameters: separating encoder, decoder, and discriminator\n",
    "        \"\"\"\n",
    "        self.encoder_params = chain(\n",
    "            self.encoder.parameters(), self.q_mu.parameters(),\n",
    "            self.q_logvar.parameters()\n",
    "        )\n",
    "\n",
    "        self.decoder_params = chain(\n",
    "            self.decoder.parameters(), self.decoder_fc.parameters()\n",
    "        )\n",
    "\n",
    "        self.vae_params = chain(\n",
    "            self.word_emb.parameters(), self.encoder_params, self.decoder_params\n",
    "        )\n",
    "        self.vae_params = filter(lambda p: p.requires_grad, self.vae_params)\n",
    "\n",
    "        \"\"\"\n",
    "        Use GPU if set\n",
    "        \"\"\"\n",
    "        if self.gpu:\n",
    "            self.cuda()\n",
    "\n",
    "    def forward_encoder(self, inputs):\n",
    "        \"\"\"\n",
    "        Inputs is batch of sentences: seq_len x mbsize\n",
    "        \"\"\"    \n",
    "        inputs = self.word_emb(inputs)\n",
    "        return self.forward_encoder_embed(inputs)\n",
    "\n",
    "    def forward_encoder_embed(self, inputs):\n",
    "        \"\"\"\n",
    "        Inputs is embeddings of: seq_len x mbsize x emb_dim\n",
    "        \"\"\"\n",
    "        _, h = self.encoder(inputs, None)\n",
    "\n",
    "        # Forward to latent\n",
    "        h = h.view(-1, self.h_dim)\n",
    "        mu = self.q_mu(h)\n",
    "        logvar = self.q_logvar(h)\n",
    "\n",
    "        return mu, logvar\n",
    "\n",
    "    def sample_z(self, mu, logvar):\n",
    "        \"\"\"\n",
    "        Reparameterization trick: z = mu + std*eps; eps ~ N(0, I)\n",
    "        \"\"\"\n",
    "        eps = Variable(torch.randn(self.z_dim))\n",
    "        eps = eps.cuda() if self.gpu else eps\n",
    "        z = mu + torch.exp(logvar/2) * eps\n",
    "        \n",
    "        return z/z.pow(2).sum().pow(0.5)\n",
    "\n",
    "    def sample_z_prior(self, mbsize):\n",
    "        \"\"\"\n",
    "        Sample z ~ p(z) = N(0, I)\n",
    "        \"\"\"\n",
    "        z = Variable(torch.randn(mbsize, self.z_dim))\n",
    "        z = z.cuda() if self.gpu else z\n",
    "        \n",
    "        return z/z.pow(2).sum().pow(0.5)\n",
    "\n",
    "    def forward_decoder(self, inputs, z):\n",
    "        \"\"\"\n",
    "        Inputs must be embeddings: seq_len x mbsize\n",
    "        \"\"\"\n",
    "        dec_inputs = self.word_dropout(inputs)\n",
    "\n",
    "        # Forward\n",
    "        seq_len = dec_inputs.size(0)\n",
    "\n",
    "        # 1 x mbsize x (z_dim+c_dim)\n",
    "        init_h = z.unsqueeze(0)\n",
    "        inputs_emb = self.word_emb(dec_inputs)  # seq_len x mbsize x emb_dim\n",
    "        inputs_emb = torch.cat([inputs_emb, init_h.repeat(seq_len, 1, 1)], 2)\n",
    "\n",
    "        outputs, _ = self.decoder(inputs_emb, init_h)\n",
    "        seq_len, mbsize, _ = outputs.size()\n",
    "\n",
    "        outputs = outputs.view(seq_len*mbsize, -1)\n",
    "        y = self.decoder_fc(outputs)\n",
    "        y = y.view(seq_len, mbsize, self.n_vocab)\n",
    "\n",
    "        return y\n",
    "\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        \"\"\"\n",
    "        Params:\n",
    "        -------\n",
    "        sentence: sequence of word indices.\n",
    "        use_c_prior: whether to sample `c` from prior or from `discriminator`.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        recon_loss: reconstruction loss of VAE.\n",
    "        kl_loss: KL-div loss of VAE.\n",
    "        \"\"\"\n",
    "        self.train()\n",
    "\n",
    "        mbsize = sentence.size(1)\n",
    "\n",
    "        # sentence: '<start> I want to fly <eos>'\n",
    "        # enc_inputs: '<start> I want to fly <eos>'\n",
    "        # dec_inputs: '<start> I want to fly <eos>'\n",
    "        # dec_targets: 'I want to fly <eos> <pad>'\n",
    "        pad_words = Variable(torch.LongTensor([self.PAD_IDX])).repeat(1, mbsize)\n",
    "        pad_words = pad_words.cuda() if self.gpu else pad_words\n",
    "\n",
    "        enc_inputs = sentence\n",
    "        dec_inputs = sentence\n",
    "        dec_targets = torch.cat([sentence[1:], pad_words], dim=0)\n",
    "\n",
    "        # Encoder: sentence -> z\n",
    "        mu, logvar = self.forward_encoder(enc_inputs)\n",
    "        z = self.sample_z(mu, logvar)\n",
    "\n",
    "        # Decoder: sentence -> y\n",
    "        y = self.forward_decoder(dec_inputs, z)       \n",
    "        \n",
    "        recon_loss = F.cross_entropy(\n",
    "            y.view(-1, self.n_vocab), dec_targets.view(-1), size_average=True\n",
    "        )\n",
    "        kl_loss = torch.mean(0.5 * torch.sum(torch.exp(logvar) + mu**2 - 1 - logvar, 1))\n",
    "\n",
    "        return recon_loss, kl_loss\n",
    "\n",
    "    def generate_sentences(self, batch_size):\n",
    "        \"\"\"\n",
    "        Generate sentences and corresponding z of (batch_size x max_sent_len)\n",
    "        \"\"\"\n",
    "        samples = []\n",
    "\n",
    "        for _ in range(batch_size):\n",
    "            z = self.sample_z_prior(1)\n",
    "            samples.append(self.sample_sentence(z, raw=True))\n",
    "\n",
    "        return samples\n",
    "\n",
    "    def sample_sentence(self, z, raw=False, temp=1):\n",
    "        \"\"\"\n",
    "        Sample single sentence from p(x|z,c) according to given temperature.\n",
    "        `raw = True` means this returns sentence as in dataset which is useful\n",
    "        to train discriminator. `False` means that this will return list of\n",
    "        `word_idx` which is useful for evaluation.\n",
    "        \"\"\"\n",
    "        self.eval()\n",
    "\n",
    "        word = torch.LongTensor([self.START_IDX])\n",
    "        word = word.cuda() if self.gpu else word\n",
    "        word = Variable(word)  # '<start>'\n",
    "\n",
    "        z= z.view(1, 1, -1)\n",
    "\n",
    "        h = z\n",
    "\n",
    "        if not isinstance(h, Variable):\n",
    "            h = Variable(h)\n",
    "\n",
    "        outputs = []\n",
    "\n",
    "        if raw:\n",
    "            outputs.append(self.START_IDX)\n",
    "\n",
    "        for i in range(self.MAX_SENT_LEN):\n",
    "            emb = self.word_emb(word).view(1, 1, -1)\n",
    "            emb = torch.cat([emb, z], 2)\n",
    "\n",
    "            output, h = self.decoder(emb, h)\n",
    "            y = self.decoder_fc(output).view(-1)\n",
    "            y = F.softmax(y/temp, dim=0)\n",
    "\n",
    "            idx = torch.multinomial(y,1)\n",
    "\n",
    "            word = Variable(torch.LongTensor([int(idx)]))\n",
    "            word = word.cuda() if self.gpu else word\n",
    "\n",
    "            idx = int(idx)\n",
    "\n",
    "            if not raw and idx == self.EOS_IDX:\n",
    "                break\n",
    "\n",
    "            outputs.append(idx)\n",
    "\n",
    "        # Back to default state: train\n",
    "        self.train()\n",
    "\n",
    "        if raw:\n",
    "            outputs = Variable(torch.LongTensor(outputs)).unsqueeze(0)\n",
    "            return outputs.cuda() if self.gpu else outputs\n",
    "        else:\n",
    "            return outputs\n",
    "\n",
    "    def generate_soft_embed(self, mbsize, temp=1):\n",
    "        \"\"\"\n",
    "        Generate soft embeddings of (mbsize x emb_dim) along with target z\n",
    "        and c for each row (mbsize x {z_dim, c_dim})\n",
    "        \"\"\"\n",
    "        samples = []\n",
    "        targets_z = []\n",
    "\n",
    "        for _ in range(mbsize):\n",
    "            z = self.sample_z_prior(1)\n",
    "\n",
    "            samples.append(self.sample_soft_embed(z, temp=1))\n",
    "            targets_z.append(z)\n",
    "\n",
    "        X_gen = torch.cat(samples, dim=0)\n",
    "        targets_z = torch.cat(targets_z, dim=0)\n",
    "\n",
    "        return X_gen, targets_z\n",
    "\n",
    "    def sample_soft_embed(self, z, temp=1):\n",
    "        \"\"\"\n",
    "        Sample single soft embedded sentence from p(x|z,c) and temperature.\n",
    "        Soft embeddings are calculated as weighted average of word_emb\n",
    "        according to p(x|z,c).\n",
    "        \"\"\"\n",
    "        self.eval()\n",
    "\n",
    "        z = z.view(1, 1, -1)\n",
    "\n",
    "        word = torch.LongTensor([self.START_IDX])\n",
    "        word = word.cuda() if self.gpu else word\n",
    "        word = Variable(word)  # '<start>'\n",
    "        emb = self.word_emb(word).view(1, 1, -1)\n",
    "        emb = torch.cat([emb, z], 2)\n",
    "\n",
    "        h = z\n",
    "\n",
    "        if not isinstance(h, Variable):\n",
    "            h = Variable(h)\n",
    "\n",
    "        outputs = [self.word_emb(word).view(1, -1)]\n",
    "\n",
    "        for i in range(self.MAX_SENT_LEN):\n",
    "            output, h = self.decoder(emb, h)\n",
    "            o = self.decoder_fc(output).view(-1)\n",
    "\n",
    "            # Sample softmax with temperature\n",
    "            y = F.softmax(o / temp, dim=0)\n",
    "\n",
    "            # Take expectation of embedding given output prob -> soft embedding\n",
    "            # <y, w> = 1 x n_vocab * n_vocab x emb_dim\n",
    "            emb = y.unsqueeze(0) @ self.word_emb.weight\n",
    "            emb = emb.view(1, 1, -1)\n",
    "\n",
    "            # Save resulting soft embedding\n",
    "            outputs.append(emb.view(1, -1))\n",
    "\n",
    "            # Append with z and c for the next input\n",
    "            emb = torch.cat([emb, z], 2)\n",
    "\n",
    "        # 1 x 16 x emb_dim\n",
    "        outputs = torch.cat(outputs, dim=0).unsqueeze(0)\n",
    "\n",
    "        # Back to default state: train\n",
    "        self.train()\n",
    "\n",
    "        return outputs.cuda() if self.gpu else outputs\n",
    "\n",
    "    def word_dropout(self, inputs):\n",
    "        \"\"\"\n",
    "        Do word dropout: with prob `p_word_dropout`, set the word to '<unk>'.\n",
    "        \"\"\"\n",
    "        if isinstance(inputs, Variable):\n",
    "            data = inputs.data.clone()\n",
    "        else:\n",
    "            data = inputs.clone()\n",
    "\n",
    "        # Sample masks: elems with val 1 will be set to <unk>\n",
    "        mask = torch.from_numpy(\n",
    "            np.random.binomial(1, p=self.p_word_dropout, size=tuple(data.size()))\n",
    "                     .astype('uint8')\n",
    "        )\n",
    "\n",
    "        if self.gpu:\n",
    "            mask = mask.cuda()\n",
    "\n",
    "        # Set to <unk>\n",
    "        data[mask] = self.UNK_IDX\n",
    "\n",
    "        return Variable(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataset female_sent_obfandclass_less100.tsv...\n"
     ]
    }
   ],
   "source": [
    "fTEXT = data.Field(init_token='<start>', eos_token='<eos>', lower=True, tokenize='spacy')\n",
    "fLABEL = data.Field(sequential=False, unk_token=None)\n",
    "\n",
    "#fTEXT = data.Field(tokenize='spacy')\n",
    "#fLABEL = data.LabelField(tensor_type=torch.FloatTensor)\n",
    "\n",
    "print(\"loading dataset female_sent_obfandclass_less100.tsv...\")\n",
    "ftrain  = data.TabularDataset.splits(\n",
    "        path='../sent/ori_gender_data/', \n",
    "        train='female_sent_obfandclass_less100.tsv',\n",
    "        format='tsv',\n",
    "        fields=[('Text', fTEXT),('Label', fLABEL)])[0]\n",
    "\n",
    "fTEXT.build_vocab(ftrain, max_size=100000, vectors=\"fasttext.en.300d\")\n",
    "fLABEL.build_vocab(ftrain)\n",
    "\n",
    "fLABEL.vocab.stoi['1']=float(1)\n",
    "fLABEL.vocab.stoi['2']=float(2)\n",
    "fLABEL.vocab.stoi['3']=float(3)\n",
    "fLABEL.vocab.stoi['4']=float(4)\n",
    "fLABEL.vocab.stoi['5']=float(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mTEXT = data.Field(init_token='<start>', eos_token='<eos>', lower=True, tokenize='spacy')\n",
    "mLABEL = data.Field(sequential=False, unk_token=None)\n",
    "\n",
    "#mTEXT = data.Field(tokenize='spacy')\n",
    "#mLABEL = data.LabelField(tensor_type=torch.FloatTensor)\n",
    "\n",
    "print(\"loading dataset male_sent_obftrain_less100.tsv...\")\n",
    "mtrain  = data.TabularDataset.splits(\n",
    "        path='../sent/ori_gender_data/', \n",
    "        train='male_sent_obftrain_less100.tsv',\n",
    "        format='tsv',\n",
    "        fields=[('Text', mTEXT),('Label', mLABEL)])[0]\n",
    "\n",
    "mTEXT.build_vocab(mtrain, max_size=100000, vectors=\"fasttext.en.300d\")\n",
    "mLABEL.build_vocab(mtrain)\n",
    "\n",
    "mLABEL.vocab.stoi['1']=float(1)\n",
    "mLABEL.vocab.stoi['2']=float(2)\n",
    "mLABEL.vocab.stoi['3']=float(3)\n",
    "mLABEL.vocab.stoi['4']=float(4)\n",
    "mLABEL.vocab.stoi['5']=float(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataset all_sent_trainVAE_less100.tsv...\n"
     ]
    }
   ],
   "source": [
    "allTEXT = data.Field(init_token='<start>', eos_token='<eos>', lower=True, tokenize='spacy')\n",
    "allLABEL = data.Field(sequential=False, unk_token=None)\n",
    "\n",
    "#allTEXT = data.Field(tokenize='spacy')\n",
    "#allLABEL = data.LabelField(tensor_type=torch.FloatTensor)\n",
    "\n",
    "print(\"loading dataset all_sent_trainVAE_less100.tsv...\")\n",
    "alltrain  = data.TabularDataset.splits(\n",
    "        path='../sent/ori_gender_data/', \n",
    "        train='all_sent_trainVAE_less100.tsv',\n",
    "        format='tsv',\n",
    "        fields=[('Text', allTEXT),('Label', allLABEL)])[0]\n",
    "\n",
    "allTEXT.build_vocab(alltrain, max_size=100000, vectors=\"fasttext.en.300d\")\n",
    "allLABEL.build_vocab(alltrain)\n",
    "\n",
    "allLABEL.vocab.stoi['1']=float(1)\n",
    "allLABEL.vocab.stoi['2']=float(2)\n",
    "allLABEL.vocab.stoi['3']=float(3)\n",
    "allLABEL.vocab.stoi['4']=float(4)\n",
    "allLABEL.vocab.stoi['5']=float(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "fTEXT.vocab = allTEXT.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guojy/anaconda3/envs/pt4/lib/python3.6/site-packages/torch/nn/modules/rnn.py:38: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    }
   ],
   "source": [
    "mb_size = 32\n",
    "h_dim = 128\n",
    "lr = 1e-3\n",
    "lr_decay_every = 2000000\n",
    "n_iter = 20000\n",
    "log_interval = 1000\n",
    "z_dim = 128\n",
    "\n",
    "# VAE model trained on all_sent_trainVAE_less100.tsv\n",
    "VAEmodel = RNN_VAE(\n",
    "    len(allTEXT.vocab), h_dim, z_dim, p_word_dropout=0.3,max_sent_len=40,\n",
    "    pretrained_embeddings=allTEXT.vocab.vectors, freeze_embeddings=False,\n",
    "    gpu=True\n",
    ")\n",
    "\n",
    "VAEmodel.load_state_dict(torch.load('models/{}.bin'.format('pre_yelp128_all_sent_trainVAE_sph_less100'))) #VAE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_codez(inputs):\n",
    "    #VAEmodel.eval()\n",
    "\n",
    "    # sentence: '<start> I want to fly <eos>'\n",
    "    # enc_inputs: '<start> I want to fly <eos>'\n",
    "    # dec_inputs: '<start> I want to fly <eos>'\n",
    "    # dec_targets: 'I want to fly <eos> <pad>'\n",
    "    pad_words = Variable(torch.LongTensor([VAEmodel.PAD_IDX])).repeat(1, mb_size)\n",
    "    pad_words = pad_words.cuda() if VAEmodel.gpu else pad_words\n",
    "\n",
    "    enc_inputs = inputs\n",
    "    dec_inputs = inputs\n",
    "    dec_targets = torch.cat([inputs[1:], pad_words], dim=0)\n",
    "\n",
    "    # Encoder: sentence -> inputs -> z\n",
    "    mu, logvar = VAEmodel.forward_encoder(enc_inputs)\n",
    "    z = VAEmodel.sample_z(mu, logvar)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 不带validation的 (可以无限for循环下去)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftrain_iter = data.BucketIterator(\n",
    "dataset=ftrain, batch_size=mb_size,\n",
    "sort_key=lambda x: data.interleave_keys(len(x.src), len(x.trg)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 带有validation的 (循环完一遍就会停止)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftrain_split, fvalid_split = ftrain.split(split_ratio=0.8)\n",
    "ftrain_split_iter = data.BucketIterator(dataset=ftrain_split, batch_size=mb_size,sort_key=lambda x: data.interleave_keys(len(x.src), len(x.trg)))\n",
    "fvalid_split_iter = data.BucketIterator(dataset=fvalid_split, batch_size=mb_size,sort_key=lambda x: data.interleave_keys(len(x.src), len(x.trg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fmodel parameters: \n",
      "<bound method Module.parameters of Net(\n",
      "  (fc1): Linear(in_features=128, out_features=100, bias=True)\n",
      "  (fc2): Linear(in_features=100, out_features=60, bias=True)\n",
      "  (fc3): Linear(in_features=60, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.5)\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "fmodel = Net(z_dim,0.5)\n",
    "print(\"fmodel parameters: \")\n",
    "print(fmodel.parameters)\n",
    "\n",
    "#pretrained_embeddings = fTEXT.vocab.vectors\n",
    "\n",
    "#fmodel.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "\n",
    "import torch.optim as optim\n",
    "foptimizer = optim.Adam(fmodel.parameters(),lr=0.0003)\n",
    "fcriterion = nn.MSELoss()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#device=torch.device('cpu')\n",
    "fmodel = fmodel.to(device)\n",
    "fcriterion = fcriterion.to(device)\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def accuracy(preds,y):\n",
    "    rounded_preds = torch.round(preds)\n",
    "    correct = (rounded_preds==y).float()\n",
    "    acc = correct.sum()/len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([24, 22])\n"
     ]
    }
   ],
   "source": [
    "for batch in ftrain_iterator:\n",
    "    inputs = batch.Text\n",
    "    if inputs.shape[1]!=32:\n",
    "        print( inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train() # turns on dropout and batch normalization and allow gradient update\n",
    "    \n",
    "    i=0\n",
    "    for batch in iterator:\n",
    "        i=i+1\n",
    "        if i>10000:\n",
    "            break\n",
    "        \n",
    "        inputs = batch.Text\n",
    "        labels = batch.Label\n",
    "    \n",
    "        try:\n",
    "            z = get_codez(inputs)\n",
    "        except:\n",
    "            print('pass training')\n",
    "            continue\n",
    "        \n",
    "        optimizer.zero_grad() # set accumulated gradient to 0 for every start of a batch\n",
    "        \n",
    "        predictions = model(z).squeeze(1)\n",
    "        \n",
    "        labels = torch.cuda.FloatTensor([x for x in labels])\n",
    "        \n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        loss = criterion(predictions, labels)\n",
    "        \n",
    "        acc = accuracy(predictions, labels)\n",
    "        \n",
    "        loss.backward() # calculate gradient\n",
    "        \n",
    "        optimizer.step() # update parameters\n",
    "        \n",
    "        if i%200==0:\n",
    "            print(\"train batch loss: \", loss.item())\n",
    "            print(\"train accuracy: \", acc.item())\n",
    "            print(i)\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    #return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "    return epoch_loss / 10000, epoch_acc / 10000\n",
    "\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval() #turns off dropout and batch normalization\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        i=0\n",
    "        for batch in iterator:\n",
    "            i=i+1\n",
    "            if i>len(iterator):\n",
    "                break\n",
    "            \n",
    "            inputs = batch.Text\n",
    "            labels = batch.Label\n",
    "\n",
    "            try:\n",
    "                z = get_codez(inputs)\n",
    "            except:\n",
    "                print('pass evaluation')\n",
    "                continue\n",
    "        \n",
    "            predictions = model(z).squeeze(1)\n",
    "        \n",
    "            labels = torch.cuda.FloatTensor([x for x in labels])\n",
    "\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            loss = criterion(predictions, labels)\n",
    "\n",
    "            acc = accuracy(predictions, labels)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            \n",
    "            if i%50 ==0:\n",
    "                print(\"eval batch loss: \", loss.item())\n",
    "                print(\"eval accuracy: \", acc.item())\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "#model = torch.load('fmodel')\n",
    "\n",
    "import timeit\n",
    "#start = timeit.default_timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "243"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ftrain_split_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch1 = next(iter(ftrain_split_iter))\n",
    "text1 = batch1.Text\n",
    "label1 = batch1.Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4,  4,  5,  5,  4,  5,  4,  3,  5,  5,  5,  5,  3,  2,\n",
       "         4,  4,  4,  5,  5,  5,  5,  5,  5,  5,  3,  1,  5,  5,\n",
       "         2,  5,  4,  5], device='cuda:0')"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4.2749,  4.1136,  4.0583,  4.1647,  4.0582,  4.1479,  4.1478,\n",
       "         4.0926,  4.1756,  4.1099,  3.9541,  4.0663,  4.0109,  4.1480,\n",
       "         4.2084,  4.0115,  4.1626,  4.1074,  4.2228,  4.1326,  4.0249,\n",
       "         3.9883,  4.2099,  4.1138,  3.9990,  4.1351,  4.0731,  4.0863,\n",
       "         4.2084,  4.2000,  4.0225,  4.1069], device='cuda:0')"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = get_codez(text1)\n",
    "fmodel(z).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    2,     6,  1532,   187,    34,    65,    55,     6,  3101,\n",
       "           23,   109,     4,     3,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1], device='cuda:0')"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> as a new yorker , i have really high pizza standards . and this place is fantastic ! <eos> <pad> <pad> <pad> <pad> <pad>'"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join([fTEXT.vocab.itos[x] for x in text1[:,11]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5, device='cuda:0')"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label1[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../sent/ori_gender_data/female_sent_obfandclass_less100.tsv','r') as f:\n",
    "    fo = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if you like pizza that taste like it has a cardboard crust than this is the place for you\t1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for line in fo:\n",
    "    if \"if you like pizza that taste like it has a cardboard crust\" in line:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train batch loss:  0.8057953119277954\n",
      "train accuracy:  0.25\n",
      "200\n",
      "pass training\n",
      "train batch loss:  1.047081708908081\n",
      "train accuracy:  0.28125\n",
      "400\n",
      "pass training\n",
      "train batch loss:  1.1258511543273926\n",
      "train accuracy:  0.40625\n",
      "600\n",
      "pass training\n",
      "train batch loss:  0.8462639451026917\n",
      "train accuracy:  0.1875\n",
      "800\n",
      "pass training\n",
      "train batch loss:  1.3155440092086792\n",
      "train accuracy:  0.21875\n",
      "1000\n",
      "train batch loss:  1.4086780548095703\n",
      "train accuracy:  0.1875\n",
      "1200\n",
      "pass training\n",
      "train batch loss:  1.35652756690979\n",
      "train accuracy:  0.25\n",
      "1400\n",
      "pass training\n",
      "train batch loss:  0.8782937526702881\n",
      "train accuracy:  0.34375\n",
      "1600\n",
      "pass training\n",
      "train batch loss:  2.0113139152526855\n",
      "train accuracy:  0.25\n",
      "1800\n",
      "pass training\n",
      "train batch loss:  1.8499486446380615\n",
      "train accuracy:  0.375\n",
      "2000\n",
      "pass training\n",
      "train batch loss:  0.8470344543457031\n",
      "train accuracy:  0.25\n",
      "2200\n",
      "pass training\n",
      "train batch loss:  1.411553144454956\n",
      "train accuracy:  0.375\n",
      "2400\n",
      "train batch loss:  1.1270596981048584\n",
      "train accuracy:  0.28125\n",
      "2600\n",
      "pass training\n",
      "train batch loss:  2.3021459579467773\n",
      "train accuracy:  0.125\n",
      "2800\n",
      "pass training\n",
      "train batch loss:  1.3294438123703003\n",
      "train accuracy:  0.25\n",
      "3000\n",
      "pass training\n",
      "train batch loss:  0.9558699131011963\n",
      "train accuracy:  0.34375\n",
      "3200\n",
      "pass training\n",
      "train batch loss:  0.873762845993042\n",
      "train accuracy:  0.25\n",
      "3400\n",
      "train batch loss:  0.9592596292495728\n",
      "train accuracy:  0.1875\n",
      "3600\n",
      "pass training\n",
      "train batch loss:  1.1282485723495483\n",
      "train accuracy:  0.3125\n",
      "3800\n",
      "pass training\n",
      "train batch loss:  1.0221437215805054\n",
      "train accuracy:  0.5\n",
      "4000\n",
      "pass training\n",
      "train batch loss:  0.7831212282180786\n",
      "train accuracy:  0.3125\n",
      "4200\n",
      "pass training\n",
      "train batch loss:  1.0538294315338135\n",
      "train accuracy:  0.1875\n",
      "4400\n",
      "pass training\n",
      "train batch loss:  0.8144986629486084\n",
      "train accuracy:  0.34375\n",
      "4600\n",
      "train batch loss:  1.137785792350769\n",
      "train accuracy:  0.21875\n",
      "4800\n",
      "pass training\n",
      "train batch loss:  1.927992582321167\n",
      "train accuracy:  0.25\n",
      "5000\n",
      "pass training\n",
      "train batch loss:  1.1047356128692627\n",
      "train accuracy:  0.34375\n",
      "5200\n",
      "pass training\n",
      "train batch loss:  1.5927588939666748\n",
      "train accuracy:  0.40625\n",
      "5400\n",
      "pass training\n",
      "train batch loss:  1.604715347290039\n",
      "train accuracy:  0.3125\n",
      "5600\n",
      "train batch loss:  1.7381410598754883\n",
      "train accuracy:  0.3125\n",
      "5800\n",
      "pass training\n",
      "train batch loss:  1.6254968643188477\n",
      "train accuracy:  0.1875\n",
      "6000\n",
      "pass training\n",
      "train batch loss:  1.0710290670394897\n",
      "train accuracy:  0.28125\n",
      "6200\n",
      "pass training\n",
      "train batch loss:  0.8038914799690247\n",
      "train accuracy:  0.3125\n",
      "6400\n",
      "pass training\n",
      "train batch loss:  1.2435126304626465\n",
      "train accuracy:  0.28125\n",
      "6600\n",
      "pass training\n",
      "train batch loss:  1.3202812671661377\n",
      "train accuracy:  0.25\n",
      "6800\n",
      "train batch loss:  0.9552856683731079\n",
      "train accuracy:  0.3125\n",
      "7000\n",
      "pass training\n",
      "train batch loss:  1.4926153421401978\n",
      "train accuracy:  0.21875\n",
      "7200\n",
      "pass training\n",
      "train batch loss:  0.7374067902565002\n",
      "train accuracy:  0.40625\n",
      "7400\n",
      "pass training\n",
      "train batch loss:  1.3749536275863647\n",
      "train accuracy:  0.375\n",
      "7600\n",
      "pass training\n",
      "train batch loss:  1.7480188608169556\n",
      "train accuracy:  0.25\n",
      "7800\n",
      "train batch loss:  0.44272881746292114\n",
      "train accuracy:  0.53125\n",
      "8000\n",
      "pass training\n",
      "train batch loss:  1.5059734582901\n",
      "train accuracy:  0.34375\n",
      "8200\n",
      "pass training\n",
      "train batch loss:  2.328878402709961\n",
      "train accuracy:  0.25\n",
      "8400\n",
      "pass training\n",
      "train batch loss:  0.8362003564834595\n",
      "train accuracy:  0.1875\n",
      "8600\n",
      "pass training\n",
      "train batch loss:  1.8314003944396973\n",
      "train accuracy:  0.25\n",
      "8800\n",
      "pass training\n",
      "train batch loss:  2.884481906890869\n",
      "train accuracy:  0.21875\n",
      "9000\n",
      "train batch loss:  2.811689615249634\n",
      "train accuracy:  0.25\n",
      "9200\n",
      "pass training\n",
      "train batch loss:  0.870911717414856\n",
      "train accuracy:  0.46875\n",
      "9400\n",
      "pass training\n",
      "train batch loss:  1.3000661134719849\n",
      "train accuracy:  0.21875\n",
      "9600\n",
      "pass training\n",
      "train batch loss:  1.705359697341919\n",
      "train accuracy:  0.25\n",
      "9800\n",
      "pass training\n",
      "train batch loss:  1.7136257886886597\n",
      "train accuracy:  0.28125\n",
      "10000\n",
      "pass evaluation\n",
      "eval batch loss:  1.1280417442321777\n",
      "eval accuracy:  0.28125\n",
      "Epoch: 01, Train Loss: 1.371, Train Acc: 27.62%, Val. Loss: 1.330, Val. Acc: 26.74%\n",
      "time duration:     91.66247527766973\n",
      "train batch loss:  1.3244240283966064\n",
      "train accuracy:  0.3125\n",
      "200\n",
      "pass training\n",
      "train batch loss:  1.4178893566131592\n",
      "train accuracy:  0.3125\n",
      "400\n",
      "pass training\n",
      "train batch loss:  1.5770256519317627\n",
      "train accuracy:  0.25\n",
      "600\n",
      "pass training\n",
      "train batch loss:  1.2823765277862549\n",
      "train accuracy:  0.3125\n",
      "800\n",
      "pass training\n",
      "train batch loss:  1.7628945112228394\n",
      "train accuracy:  0.15625\n",
      "1000\n",
      "pass training\n",
      "train batch loss:  1.4918406009674072\n",
      "train accuracy:  0.25\n",
      "1200\n",
      "train batch loss:  1.2888383865356445\n",
      "train accuracy:  0.25\n",
      "1400\n",
      "pass training\n",
      "interrupt\n",
      "Exiting from training early\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 20\n",
    "#print(\"loading previous frnn3 model...\")\n",
    "#model = torch.load('frnn3')\n",
    "try:\n",
    "    for epoch in range(N_EPOCHS):\n",
    "        start = timeit.default_timer()\n",
    "\n",
    "        train_loss, train_acc = train(fmodel, ftrain_split_iter, foptimizer, fcriterion)\n",
    "        valid_loss, valid_acc = evaluate(fmodel, fvalid_split_iter, fcriterion)\n",
    "        #print(\"saving model:   frnn8\")\n",
    "        #torch.save(model,'frnn8')\n",
    "\n",
    "        print(f'Epoch: {epoch+1:02}, Train Loss: {train_loss:.3f}, Train Acc: {train_acc*100:.2f}%, Val. Loss: {valid_loss:.3f}, Val. Acc: {valid_acc*100:.2f}%')\n",
    "        #print(f'Epoch: {epoch+1:02}, Train Loss: {train_loss:.3f}, Train Acc: {train_acc*100:.2f}%')\n",
    "\n",
    "        stop = timeit.default_timer()\n",
    "        print(\"time duration:    \", stop - start)\n",
    "\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"interrupt\")\n",
    "    print('Exiting from training early')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
